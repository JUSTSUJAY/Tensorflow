{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "BE0UtXG-_sp5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSz9HWN98SeX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization, Normalization, CenterCrop, Rescaling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "training_data = np.array([[\"This is the 1st sample.\"], [\"And here's the 2nd sample.\"]])"
      ],
      "metadata": {
        "id": "5tGEkfsG8jiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = TextVectorization()\n",
        "vector.adapt(training_data)"
      ],
      "metadata": {
        "id": "RxDPLVC38mhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgvfrklG80Nl",
        "outputId": "6913f998-a344-455f-bfa3-5e646c53ab3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=int64, numpy=\n",
              "array([[4, 5, 2, 9, 3],\n",
              "       [7, 6, 2, 8, 3]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "binary_vectorizer = TextVectorization(output_mode = 'binary',ngrams = 2)\n",
        "binary_vectorizer.adapt(training_data)\n",
        "binary_vectorizer(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQIo4CHJ89rW",
        "outputId": "3b7b4339-4e8a-4d67-8b9e-84c42a11a827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 17), dtype=float32, numpy=\n",
              "array([[0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1.],\n",
              "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
              "        0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_array = np.random.randint(0,256,size = (64,200,200,3),).astype('float')"
      ],
      "metadata": {
        "id": "53mJmuAo9RNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization = Normalization()\n",
        "normalization.adapt(image_array)\n",
        "normalized_data = normalization(image_array)\n",
        "print(\"Mean %.2f\" % np.mean(normalized_data))\n",
        "print(\"Var %.2f\" % np.var(normalized_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5q67lSN95kb",
        "outputId": "4f4941b7-cf87-4339-8eaa-f03d5cd05e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean -0.00\n",
            "Var 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example image data, with values in the [0, 255] range\n",
        "training_data = np.random.randint(0, 256, size=(64, 200, 200, 3)).astype(\"float32\")\n",
        "\n",
        "cropper = CenterCrop(height=150, width=150)\n",
        "scaler = Rescaling(scale=1.0 / 255)\n",
        "\n",
        "output_data = scaler(cropper(training_data))\n",
        "print(\"shape:\", output_data.shape)\n",
        "print(\"min:\", np.min(output_data))\n",
        "print(\"max:\", np.max(output_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aerdfck6-X9m",
        "outputId": "af4c5c70-25f4-4b98-b0f6-698becc43a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (64, 150, 150, 3)\n",
            "min: 0.0\n",
            "max: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOdeling"
      ],
      "metadata": {
        "id": "g3FabEw9_xSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "4hW73l98_Twz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense = keras.layers.Dense(units = 16)"
      ],
      "metadata": {
        "id": "6TYxKg7O_-Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RrjyNZ9ABd3",
        "outputId": "3622af01-7fe8-4867-fb2d-bb4895e4470a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.dense.Dense at 0x7dee88d9f0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = keras.Input((None,None,3))"
      ],
      "metadata": {
        "id": "aQVqP-PhAC-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtOOcSJqAjlH",
        "outputId": "901c6db7-f0f3-4fd6-af3c-3a234ebe21a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, None, None, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to crop and then scale\n",
        "cropped = CenterCrop(height = 150,width = 150)(input)\n",
        "rescaled = Rescaling(1.0/255)(cropped)"
      ],
      "metadata": {
        "id": "mdwAuEI6AlQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now that our data is preprocessed build the model\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(rescaled)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(rescaled)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(rescaled)\n",
        "\n",
        "# Apply global average pooling to get flat feature vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)"
      ],
      "metadata": {
        "id": "19z82eG2BEzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = keras.layers.Dense(10,activation = 'softmax')(x)\n",
        "model = keras.Model(inputs = input,outputs = output)"
      ],
      "metadata": {
        "id": "q5yQJAecBleL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhDwgyTbCTxO",
        "outputId": "2b591d90-9f59-4eeb-997c-65c6dded88b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " center_crop_6 (CenterCrop)  (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " rescaling_6 (Rescaling)     (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 32)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,226\n",
            "Trainable params: 1,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip = np.random.randint(0,256,size = (64,200,200,3)).astype('float')"
      ],
      "metadata": {
        "id": "havouuxWCcqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finn = model(ip)\n",
        "print(finn.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEbQTfL8C4NA",
        "outputId": "c2abb997-acdc-45a7-80f8-9384512138e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R_F5fvpDE3X",
        "outputId": "1490806d-4930-4e11-b938-970fd313e31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " center_crop_6 (CenterCrop)  (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " rescaling_6 (Rescaling)     (None, 150, 150, 3)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 32)               0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,226\n",
            "Trainable params: 1,226\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class CustomModel(keras.Model):\n",
        "  def train_step(self,data):\n",
        "    \"\"\"\n",
        "    data can be an array(x,y) or tf.data.Dataset(dataset)\n",
        "    \"\"\"\n",
        "    x,y = data\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = self(x,training = True)\n",
        "      # compute loss\n",
        "      loss = self.compute_loss(y = y, y_pred = y_pred)\n",
        "\n",
        "    # compute gradients\n",
        "    trainable_vars = self.trainable_variables  # Model variables that can be trained\n",
        "    gradients = tape.gradient(loss,trainable_vars)\n",
        "\n",
        "    # update weights by applying gradients on trainable wts\n",
        "    self.optimizer.apply_gradients(zip(gradients,trainable_vars))\n",
        "\n",
        "    # update metrics\n",
        "    for metric in self.metrics:\n",
        "      if metric.name == 'loss':\n",
        "        metric.update_state(loss)\n",
        "      else:\n",
        "        metric.update_state(y,y_pred)\n",
        "\n",
        "    return {m.name: m.result() for m in self.metrics}\n"
      ],
      "metadata": {
        "id": "rtN1ih4vDIQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = (32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs,outputs)\n",
        "model.compile(optimizer = 'adam',loss = 'mse',metrics = ['mse'])\n",
        "\n",
        "x = np.random.random((1000,32))\n",
        "y = np.random.random((1000,1))\n",
        "\n",
        "model.fit(x,y, epochs = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPyEIFj5Idhw",
        "outputId": "cc3d3bb8-c2aa-40fe-da1a-bf72f3403c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 0.3088\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2694\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7dee827a4e20>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# suppose we want to add loss function in train_step instead of compile\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnxldT1hNh6Y",
        "outputId": "bd048754-57be-440a-f459-66a88e01a970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TExt Classification"
      ],
      "metadata": {
        "id": "biCApwXZx9G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## lib\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UUcGPPSjNmgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRLGnnhfyD5l",
        "outputId": "7b5f1c3e-605d-4b52-a1b5-8763db1bdde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  14.9M      0  0:00:05  0:00:05 --:--:-- 16.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf aclImdb_v1.tar.gz\n"
      ],
      "metadata": {
        "id": "_d3ULY4SyJBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNtjo_MvyNVF",
        "outputId": "8da0e435-a7ee-45bb-e997-9d5ce360b150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LetiT8W8yRXe",
        "outputId": "fba46285-1b30-4527-f303-cd8ec645e902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aug68uNvyVJS",
        "outputId": "feb64231-405f-4581-d740-dffbf9661115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat aclImdb/train/pos/11818_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCooVB1cyYG_",
        "outputId": "93c640d7-ac45-43fd-bda4-3b47269a368a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most successful comic book movies usually depend on having villains that are bigger than life, ready to jump off the screen and strangle you alive with a smile or a demented line or two of dialog. The Tim Burton Batmans had it, as did (in an even more grotesque manner) Sin City. With Dick Tracy producer/director/star Warren Beatty piles on the villains until it becomes part of the framework. Like a boisterous homage to 1930s gangster pictures- only this time meant for kids as opposed to the darker Bonnie and Clyde- Dick Tracy is filled, joyfully, with archetypes and bright, primary colors, where the criminals carry tommy guns and are formed on their faces to shape their personalities. Villains like The Stooge, Shoulders, Lips, The Brow, Mumbles, the Blank, Pruneface, Spud. Chester Gould gave the names to his characters that fit their profiles, and gave his hero a jaw that could cut glass. The film is a continuation of sight gags that are perfectly taken seriously.<br /><br />If, at the time, movies like Batman and (underrated) Teenage Mutant Ninja Turtles were darker depictions of reality within a comic-book outline, Dick Tracy is more 'old-school'. It's a story of cops and crooks, or rather A cop, detective Tracy as he tries to bust Big Boy (Al Pacino, in what is arguably his BIGGEST performance to date, and in a sense the one that makes sense for his grandiose style), but with no such luck. There's also a little kid, called simply the Kid (Charlie Korsmo, who somehow brings more spunk to this little kid than would've been imagined), and Tracy's love interest in Tess. And then there's the nightclub 'dame' (Madonna, who probably doesn't give any kind of great acting performance, but maybe that suits the role fine, and she sings excellently when called upon), who wont testify unless Tracy admits feelings he doesn't have for her. Then there's convoluted dealings with taking Tracy down, and a mysterious masked figure with a scraggly voice.<br /><br />Meantime, as if doing an impersonation of a Howard Hawks film in a splash of visual effects and bigger explosions, Dick Tracy adds on the wink-and-nod comedy and the action like its syrup on a tall stack of pancakes. It's a wonder to look at this world, which is created in ways that have a fascination to them that had they been done today would just be simply by proxy of computers (i.e. Sin City, which can be justifiably compared to Beatty's film). We're driven through this world in great big shots and then thrust in the plot line, or whatever there is of it, in big editing montages with camera angles that seem to come out of those little tilted panels in the comics of old. I'm almost reminded of the Cotton Club during these sequences, as story, music, detail, and a few BIG punches and gun-shots go a long way to revealing what needs to be said, which, actually, isn't more than it needs to. And there's a heap-load of catchy dialog from the script (one of my favorites: \"the enemy of my enemy is... my enemy\", plus any of Pacino's references to other figures in quotes).<br /><br />Revisiting this after seeing it for the first time in the movie theater (and only remembering little bits), Dick Tracy is a hard-boiled fantasy to the finest degree. It's filled with good cheer for the kids, and with some pretty good action squared away without some of the more sinister intent of its cousin comic-book movies (i.e. PG-13 fare), and for the adults its throw-back central done with panache and a solid feeling for the unsubtle. Even Dustin Hoffman hams it up, and he barely says an audible word!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup\n",
        "# removes unsup folder since we don't need it"
      ],
      "metadata": {
        "id": "gMnW87Bsyh-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide training data into training and validation set\n",
        "BATCH = 32\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = BATCH,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    seed = 199\n",
        ")\n",
        "\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size = BATCH,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    seed = 199\n",
        ")\n",
        "\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size = BATCH\n",
        ")\n",
        "\n",
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvx8fCpoyzGS",
        "outputId": "1b20e7a4-41a3-48a9-d2d3-dbb419133d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Number of batches in raw_train_ds: 625\n",
            "Number of batches in raw_val_ds: 157\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch,label_batch in raw_train_ds.take(1): #first batch\n",
        "  for i in range(5): #iterate through 32 samples\n",
        "    print(text_batch.numpy()[i])\n",
        "    print(label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7pvA0tRz_1S",
        "outputId": "f8d8e558-d320-4b86-c523-b1f394ada39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"I do agree with everything Calamine has said! And I don't always agree with people, but what Calamine has said is very true, it is time for the girls to move on to better roles. I would like to see them succeed very much as they were a very inspirational pair growing up and I would like to see them grow as people, actresses and in their career as well as their personal life. So producers, please give the girls a chance to develop something that goes off the tangent a bit, move them into a new direction that recognises them individually and their talents in many facets. This movie that is being commented is not too bad, but as I have seen further on in their movies, their movies stay the same of typical plot and typography. When In Rome is good for audiences of younger generation but the adults who were kids when the twins were babies want to follow the twins in their successes and so hence I think we adults would like to see them make movies of different kinds, maybe some that are like the sixth sense, the hour, chocolat, that sort of movie - not saying to have just serious movies for them, humour ones too yes, but rather see them in different roles to what they have been playing in their more recent movies like this one and New York Minute. (Note: I am from Australia so excuse my weird spelling like reognise with the s instead of z)\"\n",
            "0\n",
            "b\"HUSBANDS BEWARE is a remake of the Shemp classic BRIDELESS GROOM. The film's new cooking scene at the beginning of the film is great. The stooges are always funny when they cook. However after the first few minutes of cooking footage, we cut to original footage of BRIDELESS GROOM. One thing I noticed about these 1953 to 1956 remakes are that they do fit with the new story. They do an insert shot if the old story line doesn't match.<br /><br />HUSBANDS BEWARE does have a new ending, but I won't give it away to those who want to be surprised.<br /><br /> **** out of 4 stars.\"\n",
            "1\n",
            "b'i actually thought this is a comedy and sat watching it expecting to laugh my ass off. pretty soon in became clear this is no comedy, or at least not a \\'Jim Carrey type\\' one. what kept we watching was the characters - the movie starts with some pretty grim, troubled people, gathered together to try and fight one of their basic fears - fear of water, fear of swimming. we start to get bit by bit into their lives, witness their troubles, guess of their thoughts.<br /><br />actually i made it look much darker than it actually is, and besides the chain of events soon brings some light and hope to their lives.<br /><br />i probably wouldn\\'t have watched the movie had i known its not a comedy but rather a drama, but i had good time, enjoyed the story and don\\'t mind i spent about 90 minutes with it.<br /><br />many films treat the alienation between people in the western world, this movie shows how people can get together and help each other<br /><br />\"and if in the light of dying day you meet her, don\\'t let her pass you by and leave, don\\'t loose her, she is your gift from the sun...\"<br /><br />9/10<br /><br />peace and love'\n",
            "1\n",
            "b'\"Pandora\\'s Clock\" is a gripping suspense/thriller that\\'s a cross between a virus movie and a disaster film. This movie, which aired in two parts on NBC in its debut showing in 1996, is about an airplane flight that becomes infected with a virus when one of the passengers just happens to be carrying this disease. The U.S. Government debates on whether the plane should be destroyed or not, while the pilot (Richard Dean Anderson) and a virus expert (Daphne Zuniga) try to figure something out to avoid disaster. I\\'m not really a big fan of TV movies and miniseries, but I liked \"Pandora\\'s Clock\". It\\'s one heck of a thrill ride. Jane Leeves (TV\\'s \"Frasier\"), Robert Loggia, and Edward Herrmann (as the President) also star.<br /><br />*** (out of four)'\n",
            "1\n",
            "b'This is a fascinating film--especially to old movie buffs and historians (I am both). During the first half of the twentieth century, sadly, Black Americans were usually not allowed into White theaters. As a result, theaters catering to Black audiences wanted to show films reflecting the Black experience and showing Black actors. In many cases, the films were essentially similar plot-wise to standard Hollywood fare, but with a much, much lower budget--and usually horrid production values. You really can\\'t fault the film makers--they just didn\\'t have the money and resources available to the average film company. As a result, they had to make due with a lot less--including an over-reliance on stock actors that were seen again and again, no money for re-shooting scenes and a need to get the films done FAST! This film tried very hard to be a Black version of a Gene Autry film--starring Herb Jeffries instead. Jeffries was a light-skinned man from mixed ancestry and he starred in several similar cowboy films. In each, he sings a little, fights a little (though VERY poorly) and loves a little--everything you need in a cowboy. Believe it or not, Jeffries is STILL alive at age 96.<br /><br />The general plot was indiscernible from an Autry picture--complete with anachronistic items such as telephones out West! The problem is that despite its similarities, the low budget shines through. Stymie (from the Li\\'l Rascals) flubbed a few lines but they just left it in, the fight scenes were totally unchoreographed and were among the worst ever put on film, there were some odd plot holes, there was no background music (leaving the film strangely quiet) and the acting was pretty awful.<br /><br />Now this does NOT mean that the film isn\\'t worth seeing--only that it abouts with technical problems that prevent it from being scored higher. One reviewer, oddly, scored this film a 10! How this can be with all the problems is beyond me. However, I can understand a person liking the film despite its many problems. The plot is generally pretty good, the characters likable, the musical numbers excellent and you know that the people making the film tried so darn hard AND it\\'s a very important piece of American history. But a 10!? <br /><br />By the way, in an odd bit of casting, the very tall, lean and almost white-skinned Jefferies is paired with short, dumpy and exceptionally dark Mantan Moreland....as his brother!! Also, Spencer Williams may be familiar to you. He played Andy on TV\\'s \"Amos \\'n Andy\".'\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```their thoughts.<br /><br />actually```\n",
        "there are break tags present in the text and other things present in the data. so we need processing\n",
        "\n",
        "default standardizer does not remove this tags\n",
        "\n",
        "solution is to build a custom standardizer"
      ],
      "metadata": {
        "id": "NaQPrXU61llZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "import string\n",
        "import re"
      ],
      "metadata": {
        "id": "EnV_jcre0Tsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase,'<br />',' ')\n",
        "  return tf.strings.regex_replace(stripped_html,f'[{re.escape(string.punctuation)}]','')\n",
        "\n",
        "# model constants\n",
        "max_features = 20000\n",
        "embedding_dim = 128 #each word will be represented in 128 dimensional vector\n",
        "sequence_length = 500\n",
        "\n",
        "# we will use standardization layer to clean the data\n",
        "# next comes the vectorization, in which wll map text to numbers, so op mode -> int\n",
        "\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens = max_features,\n",
        "    standardize = custom_standardization,\n",
        "    split = 'whitespace',\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length = sequence_length,\n",
        "\n",
        ")\n",
        "\n",
        "# now we also have vectorization layer which will vectorize the text and we are ready to feed in the model\n",
        "# consider only the text portion in train, and forget about the label for vectorization\n",
        "\n",
        "text_ds = raw_train_ds.map(lambda text,label: text)\n",
        "# let vectorization layer adapt it\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "kcOXRL0G2Dg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there are two options to deal with the txt data\n",
        "# case 1\n",
        "# first tokenize them and then feed in the model, what we did above\n",
        "# case 2\n",
        "# or add the tokenization layer in the model iteself and pass the text data to model itself\n",
        "\n",
        "# text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "# x = vectorize_layer(text_input)\n",
        "# x = layers.Embedding(max_features + 1, embedding_dim)(x)\n"
      ],
      "metadata": {
        "id": "TCyosE2I5As5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text,label):\n",
        "  text = tf.expand_dims(text,-1)\n",
        "  return vectorize_layer(text),label\n",
        "\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)\n",
        "\n",
        "# .cache(): This method caches the data in memory or on disk,\n",
        "#  depending on the available resources and the backend being used.\n",
        "#  Caching is beneficial because it allows for faster data retrieval during training,\n",
        "\n",
        "'''.prefetch(buffer_size=10):\n",
        "This method prefetches data from the next batch, which means it loads the next set of data into memory while the model is training on the current batch.\n",
        "This prefetching process overlaps data loading and training, reducing the idle time of the GPU or CPU during training and maximizing hardware utilization.\n",
        " The buffer_size parameter determines how many batches to prefetch ahead of time. In this case, it is set to 10, meaning that the next 10 batches will be preloaded while the current batch is being processed.'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "E5jQB6Js56nS",
        "outputId": "dafb0076-90f4-4d79-e58e-c864eaff3d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.prefetch(buffer_size=10): \\nThis method prefetches data from the next batch, which means it loads the next set of data into memory while the model is training on the current batch. \\nThis prefetching process overlaps data loading and training, reducing the idle time of the GPU or CPU during training and maximizing hardware utilization.\\n The buffer_size parameter determines how many batches to prefetch ahead of time. In this case, it is set to 10, meaning that the next 10 batches will be preloaded while the current batch is being processed.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "# we have already vectorized the text, so we have ints to input\n",
        "inputs = tf.keras.Input(shape = (None,),dtype = 'int64')\n",
        "\n",
        "# EMBEDDING\n",
        "# in word embeddings - words or the tokens that we pass are represented as dense vectors in continuous vector space\n",
        "# this dense vector helps capture semantic relationships between words\n",
        "x = tf.keras.layers.Embedding(max_features,embedding_dim)(inputs)\n",
        "\n",
        "# DROPOUT\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# convolution layer\n",
        "x = tf.keras.layers.Conv1D(filters = 128,kernel_size = 7,strides = 3, padding = 'valid',activation = 'relu')(x)\n",
        "# Max pooling\n",
        "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = tf.keras.layers.Dense(128,activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "# output layer\n",
        "predictions = tf.keras.layers.Dense(1,activation = 'softmax',name = 'predictions')(x)\n",
        "\n",
        "# define a model\n",
        "model = tf.keras.Model(inputs,predictions)\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wtjYSC87PNB",
        "outputId": "2e00e0ad-bfa4-4437-fbf2-8ad644581e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_11 (Embedding)    (None, None, 50)          1000000   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 50)          0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, None, 128)         44928     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,061,569\n",
            "Trainable params: 1,061,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds,validation_data = val_ds,epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXqeu1IR8od0",
        "outputId": "9706f804-b036-440b-cfef-99d6ab79e5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 52s 81ms/step - loss: 0.5491 - accuracy: 0.4996 - val_loss: 0.3376 - val_accuracy: 0.5016\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 59s 94ms/step - loss: 0.2760 - accuracy: 0.4996 - val_loss: 0.2871 - val_accuracy: 0.5016\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 65s 104ms/step - loss: 0.1773 - accuracy: 0.4996 - val_loss: 0.3174 - val_accuracy: 0.5016\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 52s 84ms/step - loss: 0.1198 - accuracy: 0.4996 - val_loss: 0.3372 - val_accuracy: 0.5016\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 42s 68ms/step - loss: 0.0827 - accuracy: 0.4996 - val_loss: 0.3948 - val_accuracy: 0.5016\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5347ca7400>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q5UFSDcyCFDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugs9ZQZ1COhJ",
        "outputId": "cf1e67fe-11b6-42a5-f78c-a382f6d2a308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3939 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3939269781112671, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# end_to_end meaning directly input text data\n",
        "\n",
        "inputs = tf.keras.Input(shape = (1,),dtype = 'string')\n",
        "indices = vectorize_layer(inputs)\n",
        "outputs = model(indices)\n",
        "\n",
        "end_to_end_model = tf.keras.Model(inputs,outputs)\n",
        "end_to_end_model.compile(loss = 'binary_crossentropy',\n",
        "                         optimizer = 'adam',\n",
        "                         metrics = ['accuracy'])\n",
        "end_to_end_model.evaluate(raw_test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZLoA9pYCRM4",
        "outputId": "dccbdb77-047d-460e-a1d7-f1bbf03fbd11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3939 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3939265310764313, 0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AeaarRs5DKSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}